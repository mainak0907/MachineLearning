{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ley0-8KSCTG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the four different states of the XOR gate\n",
        "training_data = np.array([[0,0],[0,1],[1,0],[1,1]], \"float32\")\n",
        "\n",
        "# the four expected results in the same order\n",
        "target_data = np.array([[0],[1],[1],[0]], \"float32\")"
      ],
      "metadata": {
        "id": "irT20HXGSH_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "MFU4OEURSL7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['binary_accuracy'])"
      ],
      "metadata": {
        "id": "GR4tiETJSOE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_data, target_data, epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t6RzoBKSRex",
        "outputId": "814577a6-b72a-40a0-9a96-d629e18950f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 - 2s - loss: 0.2551 - binary_accuracy: 0.5000 - 2s/epoch - 2s/step\n",
            "Epoch 2/200\n",
            "1/1 - 0s - loss: 0.2547 - binary_accuracy: 0.2500 - 26ms/epoch - 26ms/step\n",
            "Epoch 3/200\n",
            "1/1 - 0s - loss: 0.2543 - binary_accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 4/200\n",
            "1/1 - 0s - loss: 0.2539 - binary_accuracy: 0.2500 - 22ms/epoch - 22ms/step\n",
            "Epoch 5/200\n",
            "1/1 - 0s - loss: 0.2536 - binary_accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 6/200\n",
            "1/1 - 0s - loss: 0.2532 - binary_accuracy: 0.2500 - 17ms/epoch - 17ms/step\n",
            "Epoch 7/200\n",
            "1/1 - 0s - loss: 0.2528 - binary_accuracy: 0.2500 - 29ms/epoch - 29ms/step\n",
            "Epoch 8/200\n",
            "1/1 - 0s - loss: 0.2524 - binary_accuracy: 0.2500 - 20ms/epoch - 20ms/step\n",
            "Epoch 9/200\n",
            "1/1 - 0s - loss: 0.2521 - binary_accuracy: 0.2500 - 26ms/epoch - 26ms/step\n",
            "Epoch 10/200\n",
            "1/1 - 0s - loss: 0.2517 - binary_accuracy: 0.2500 - 12ms/epoch - 12ms/step\n",
            "Epoch 11/200\n",
            "1/1 - 0s - loss: 0.2513 - binary_accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 12/200\n",
            "1/1 - 0s - loss: 0.2510 - binary_accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 13/200\n",
            "1/1 - 0s - loss: 0.2506 - binary_accuracy: 0.2500 - 70ms/epoch - 70ms/step\n",
            "Epoch 14/200\n",
            "1/1 - 0s - loss: 0.2503 - binary_accuracy: 0.2500 - 21ms/epoch - 21ms/step\n",
            "Epoch 15/200\n",
            "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.2500 - 14ms/epoch - 14ms/step\n",
            "Epoch 16/200\n",
            "1/1 - 0s - loss: 0.2496 - binary_accuracy: 0.2500 - 35ms/epoch - 35ms/step\n",
            "Epoch 17/200\n",
            "1/1 - 0s - loss: 0.2493 - binary_accuracy: 0.2500 - 22ms/epoch - 22ms/step\n",
            "Epoch 18/200\n",
            "1/1 - 0s - loss: 0.2490 - binary_accuracy: 0.2500 - 20ms/epoch - 20ms/step\n",
            "Epoch 19/200\n",
            "1/1 - 0s - loss: 0.2487 - binary_accuracy: 0.2500 - 15ms/epoch - 15ms/step\n",
            "Epoch 20/200\n",
            "1/1 - 0s - loss: 0.2483 - binary_accuracy: 0.2500 - 16ms/epoch - 16ms/step\n",
            "Epoch 21/200\n",
            "1/1 - 0s - loss: 0.2480 - binary_accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 22/200\n",
            "1/1 - 0s - loss: 0.2477 - binary_accuracy: 0.2500 - 20ms/epoch - 20ms/step\n",
            "Epoch 23/200\n",
            "1/1 - 0s - loss: 0.2474 - binary_accuracy: 0.2500 - 15ms/epoch - 15ms/step\n",
            "Epoch 24/200\n",
            "1/1 - 0s - loss: 0.2471 - binary_accuracy: 0.2500 - 11ms/epoch - 11ms/step\n",
            "Epoch 25/200\n",
            "1/1 - 0s - loss: 0.2468 - binary_accuracy: 0.2500 - 16ms/epoch - 16ms/step\n",
            "Epoch 26/200\n",
            "1/1 - 0s - loss: 0.2465 - binary_accuracy: 0.2500 - 19ms/epoch - 19ms/step\n",
            "Epoch 27/200\n",
            "1/1 - 0s - loss: 0.2462 - binary_accuracy: 0.2500 - 9ms/epoch - 9ms/step\n",
            "Epoch 28/200\n",
            "1/1 - 0s - loss: 0.2460 - binary_accuracy: 0.2500 - 18ms/epoch - 18ms/step\n",
            "Epoch 29/200\n",
            "1/1 - 0s - loss: 0.2457 - binary_accuracy: 0.2500 - 17ms/epoch - 17ms/step\n",
            "Epoch 30/200\n",
            "1/1 - 0s - loss: 0.2454 - binary_accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 31/200\n",
            "1/1 - 0s - loss: 0.2451 - binary_accuracy: 0.2500 - 21ms/epoch - 21ms/step\n",
            "Epoch 32/200\n",
            "1/1 - 0s - loss: 0.2449 - binary_accuracy: 0.2500 - 13ms/epoch - 13ms/step\n",
            "Epoch 33/200\n",
            "1/1 - 0s - loss: 0.2446 - binary_accuracy: 0.5000 - 18ms/epoch - 18ms/step\n",
            "Epoch 34/200\n",
            "1/1 - 0s - loss: 0.2443 - binary_accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 35/200\n",
            "1/1 - 0s - loss: 0.2441 - binary_accuracy: 0.5000 - 19ms/epoch - 19ms/step\n",
            "Epoch 36/200\n",
            "1/1 - 0s - loss: 0.2438 - binary_accuracy: 0.5000 - 18ms/epoch - 18ms/step\n",
            "Epoch 37/200\n",
            "1/1 - 0s - loss: 0.2436 - binary_accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 38/200\n",
            "1/1 - 0s - loss: 0.2433 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 39/200\n",
            "1/1 - 0s - loss: 0.2431 - binary_accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 40/200\n",
            "1/1 - 0s - loss: 0.2428 - binary_accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 41/200\n",
            "1/1 - 0s - loss: 0.2426 - binary_accuracy: 0.5000 - 27ms/epoch - 27ms/step\n",
            "Epoch 42/200\n",
            "1/1 - 0s - loss: 0.2424 - binary_accuracy: 0.5000 - 30ms/epoch - 30ms/step\n",
            "Epoch 43/200\n",
            "1/1 - 0s - loss: 0.2421 - binary_accuracy: 0.5000 - 20ms/epoch - 20ms/step\n",
            "Epoch 44/200\n",
            "1/1 - 0s - loss: 0.2419 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 45/200\n",
            "1/1 - 0s - loss: 0.2417 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 46/200\n",
            "1/1 - 0s - loss: 0.2415 - binary_accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 47/200\n",
            "1/1 - 0s - loss: 0.2413 - binary_accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 48/200\n",
            "1/1 - 0s - loss: 0.2410 - binary_accuracy: 0.5000 - 11ms/epoch - 11ms/step\n",
            "Epoch 49/200\n",
            "1/1 - 0s - loss: 0.2408 - binary_accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 50/200\n",
            "1/1 - 0s - loss: 0.2406 - binary_accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 51/200\n",
            "1/1 - 0s - loss: 0.2404 - binary_accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 52/200\n",
            "1/1 - 0s - loss: 0.2402 - binary_accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 53/200\n",
            "1/1 - 0s - loss: 0.2400 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 54/200\n",
            "1/1 - 0s - loss: 0.2398 - binary_accuracy: 0.5000 - 20ms/epoch - 20ms/step\n",
            "Epoch 55/200\n",
            "1/1 - 0s - loss: 0.2396 - binary_accuracy: 0.5000 - 22ms/epoch - 22ms/step\n",
            "Epoch 56/200\n",
            "1/1 - 0s - loss: 0.2394 - binary_accuracy: 0.5000 - 37ms/epoch - 37ms/step\n",
            "Epoch 57/200\n",
            "1/1 - 0s - loss: 0.2392 - binary_accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 58/200\n",
            "1/1 - 0s - loss: 0.2390 - binary_accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 59/200\n",
            "1/1 - 0s - loss: 0.2389 - binary_accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 60/200\n",
            "1/1 - 0s - loss: 0.2387 - binary_accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 61/200\n",
            "1/1 - 0s - loss: 0.2385 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 62/200\n",
            "1/1 - 0s - loss: 0.2383 - binary_accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 63/200\n",
            "1/1 - 0s - loss: 0.2381 - binary_accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 64/200\n",
            "1/1 - 0s - loss: 0.2379 - binary_accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 65/200\n",
            "1/1 - 0s - loss: 0.2378 - binary_accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 66/200\n",
            "1/1 - 0s - loss: 0.2376 - binary_accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 67/200\n",
            "1/1 - 0s - loss: 0.2374 - binary_accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 68/200\n",
            "1/1 - 0s - loss: 0.2372 - binary_accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 69/200\n",
            "1/1 - 0s - loss: 0.2371 - binary_accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 70/200\n",
            "1/1 - 0s - loss: 0.2369 - binary_accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 71/200\n",
            "1/1 - 0s - loss: 0.2367 - binary_accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 72/200\n",
            "1/1 - 0s - loss: 0.2366 - binary_accuracy: 0.5000 - 24ms/epoch - 24ms/step\n",
            "Epoch 73/200\n",
            "1/1 - 0s - loss: 0.2364 - binary_accuracy: 0.5000 - 30ms/epoch - 30ms/step\n",
            "Epoch 74/200\n",
            "1/1 - 0s - loss: 0.2362 - binary_accuracy: 0.5000 - 18ms/epoch - 18ms/step\n",
            "Epoch 75/200\n",
            "1/1 - 0s - loss: 0.2361 - binary_accuracy: 0.5000 - 17ms/epoch - 17ms/step\n",
            "Epoch 76/200\n",
            "1/1 - 0s - loss: 0.2359 - binary_accuracy: 0.5000 - 25ms/epoch - 25ms/step\n",
            "Epoch 77/200\n",
            "1/1 - 0s - loss: 0.2357 - binary_accuracy: 0.5000 - 24ms/epoch - 24ms/step\n",
            "Epoch 78/200\n",
            "1/1 - 0s - loss: 0.2356 - binary_accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 79/200\n",
            "1/1 - 0s - loss: 0.2354 - binary_accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 80/200\n",
            "1/1 - 0s - loss: 0.2353 - binary_accuracy: 0.5000 - 15ms/epoch - 15ms/step\n",
            "Epoch 81/200\n",
            "1/1 - 0s - loss: 0.2351 - binary_accuracy: 0.5000 - 19ms/epoch - 19ms/step\n",
            "Epoch 82/200\n",
            "1/1 - 0s - loss: 0.2349 - binary_accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 83/200\n",
            "1/1 - 0s - loss: 0.2348 - binary_accuracy: 0.5000 - 20ms/epoch - 20ms/step\n",
            "Epoch 84/200\n",
            "1/1 - 0s - loss: 0.2346 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 85/200\n",
            "1/1 - 0s - loss: 0.2345 - binary_accuracy: 0.5000 - 20ms/epoch - 20ms/step\n",
            "Epoch 86/200\n",
            "1/1 - 0s - loss: 0.2343 - binary_accuracy: 0.5000 - 13ms/epoch - 13ms/step\n",
            "Epoch 87/200\n",
            "1/1 - 0s - loss: 0.2342 - binary_accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 88/200\n",
            "1/1 - 0s - loss: 0.2340 - binary_accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 89/200\n",
            "1/1 - 0s - loss: 0.2338 - binary_accuracy: 0.5000 - 14ms/epoch - 14ms/step\n",
            "Epoch 90/200\n",
            "1/1 - 0s - loss: 0.2337 - binary_accuracy: 0.5000 - 41ms/epoch - 41ms/step\n",
            "Epoch 91/200\n",
            "1/1 - 0s - loss: 0.2335 - binary_accuracy: 0.5000 - 39ms/epoch - 39ms/step\n",
            "Epoch 92/200\n",
            "1/1 - 0s - loss: 0.2334 - binary_accuracy: 0.5000 - 32ms/epoch - 32ms/step\n",
            "Epoch 93/200\n",
            "1/1 - 0s - loss: 0.2332 - binary_accuracy: 0.5000 - 33ms/epoch - 33ms/step\n",
            "Epoch 94/200\n",
            "1/1 - 0s - loss: 0.2331 - binary_accuracy: 0.5000 - 20ms/epoch - 20ms/step\n",
            "Epoch 95/200\n",
            "1/1 - 0s - loss: 0.2329 - binary_accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 96/200\n",
            "1/1 - 0s - loss: 0.2327 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
            "Epoch 97/200\n",
            "1/1 - 0s - loss: 0.2326 - binary_accuracy: 0.5000 - 9ms/epoch - 9ms/step\n",
            "Epoch 98/200\n",
            "1/1 - 0s - loss: 0.2324 - binary_accuracy: 0.5000 - 10ms/epoch - 10ms/step\n",
            "Epoch 99/200\n",
            "1/1 - 0s - loss: 0.2323 - binary_accuracy: 0.5000 - 25ms/epoch - 25ms/step\n",
            "Epoch 100/200\n",
            "1/1 - 0s - loss: 0.2321 - binary_accuracy: 0.7500 - 40ms/epoch - 40ms/step\n",
            "Epoch 101/200\n",
            "1/1 - 0s - loss: 0.2320 - binary_accuracy: 0.7500 - 20ms/epoch - 20ms/step\n",
            "Epoch 102/200\n",
            "1/1 - 0s - loss: 0.2318 - binary_accuracy: 0.7500 - 32ms/epoch - 32ms/step\n",
            "Epoch 103/200\n",
            "1/1 - 0s - loss: 0.2317 - binary_accuracy: 0.7500 - 30ms/epoch - 30ms/step\n",
            "Epoch 104/200\n",
            "1/1 - 0s - loss: 0.2315 - binary_accuracy: 0.7500 - 35ms/epoch - 35ms/step\n",
            "Epoch 105/200\n",
            "1/1 - 0s - loss: 0.2314 - binary_accuracy: 0.7500 - 23ms/epoch - 23ms/step\n",
            "Epoch 106/200\n",
            "1/1 - 0s - loss: 0.2312 - binary_accuracy: 0.7500 - 19ms/epoch - 19ms/step\n",
            "Epoch 107/200\n",
            "1/1 - 0s - loss: 0.2310 - binary_accuracy: 0.7500 - 49ms/epoch - 49ms/step\n",
            "Epoch 108/200\n",
            "1/1 - 0s - loss: 0.2309 - binary_accuracy: 0.7500 - 34ms/epoch - 34ms/step\n",
            "Epoch 109/200\n",
            "1/1 - 0s - loss: 0.2308 - binary_accuracy: 0.7500 - 22ms/epoch - 22ms/step\n",
            "Epoch 110/200\n",
            "1/1 - 0s - loss: 0.2306 - binary_accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
            "Epoch 111/200\n",
            "1/1 - 0s - loss: 0.2305 - binary_accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
            "Epoch 112/200\n",
            "1/1 - 0s - loss: 0.2303 - binary_accuracy: 0.7500 - 25ms/epoch - 25ms/step\n",
            "Epoch 113/200\n",
            "1/1 - 0s - loss: 0.2301 - binary_accuracy: 0.7500 - 21ms/epoch - 21ms/step\n",
            "Epoch 114/200\n",
            "1/1 - 0s - loss: 0.2300 - binary_accuracy: 0.7500 - 18ms/epoch - 18ms/step\n",
            "Epoch 115/200\n",
            "1/1 - 0s - loss: 0.2298 - binary_accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
            "Epoch 116/200\n",
            "1/1 - 0s - loss: 0.2297 - binary_accuracy: 0.7500 - 23ms/epoch - 23ms/step\n",
            "Epoch 117/200\n",
            "1/1 - 0s - loss: 0.2295 - binary_accuracy: 0.7500 - 35ms/epoch - 35ms/step\n",
            "Epoch 118/200\n",
            "1/1 - 0s - loss: 0.2293 - binary_accuracy: 0.7500 - 52ms/epoch - 52ms/step\n",
            "Epoch 119/200\n",
            "1/1 - 0s - loss: 0.2292 - binary_accuracy: 0.7500 - 34ms/epoch - 34ms/step\n",
            "Epoch 120/200\n",
            "1/1 - 0s - loss: 0.2290 - binary_accuracy: 0.7500 - 34ms/epoch - 34ms/step\n",
            "Epoch 121/200\n",
            "1/1 - 0s - loss: 0.2289 - binary_accuracy: 0.7500 - 21ms/epoch - 21ms/step\n",
            "Epoch 122/200\n",
            "1/1 - 0s - loss: 0.2287 - binary_accuracy: 0.7500 - 23ms/epoch - 23ms/step\n",
            "Epoch 123/200\n",
            "1/1 - 0s - loss: 0.2285 - binary_accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
            "Epoch 124/200\n",
            "1/1 - 0s - loss: 0.2284 - binary_accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
            "Epoch 125/200\n",
            "1/1 - 0s - loss: 0.2282 - binary_accuracy: 0.7500 - 23ms/epoch - 23ms/step\n",
            "Epoch 126/200\n",
            "1/1 - 0s - loss: 0.2281 - binary_accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
            "Epoch 127/200\n",
            "1/1 - 0s - loss: 0.2279 - binary_accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
            "Epoch 128/200\n",
            "1/1 - 0s - loss: 0.2277 - binary_accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
            "Epoch 129/200\n",
            "1/1 - 0s - loss: 0.2275 - binary_accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
            "Epoch 130/200\n",
            "1/1 - 0s - loss: 0.2274 - binary_accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
            "Epoch 131/200\n",
            "1/1 - 0s - loss: 0.2272 - binary_accuracy: 0.7500 - 56ms/epoch - 56ms/step\n",
            "Epoch 132/200\n",
            "1/1 - 0s - loss: 0.2270 - binary_accuracy: 0.7500 - 52ms/epoch - 52ms/step\n",
            "Epoch 133/200\n",
            "1/1 - 0s - loss: 0.2269 - binary_accuracy: 0.7500 - 61ms/epoch - 61ms/step\n",
            "Epoch 134/200\n",
            "1/1 - 0s - loss: 0.2267 - binary_accuracy: 0.7500 - 40ms/epoch - 40ms/step\n",
            "Epoch 135/200\n",
            "1/1 - 0s - loss: 0.2265 - binary_accuracy: 0.7500 - 22ms/epoch - 22ms/step\n",
            "Epoch 136/200\n",
            "1/1 - 0s - loss: 0.2264 - binary_accuracy: 0.7500 - 44ms/epoch - 44ms/step\n",
            "Epoch 137/200\n",
            "1/1 - 0s - loss: 0.2262 - binary_accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
            "Epoch 138/200\n",
            "1/1 - 0s - loss: 0.2260 - binary_accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
            "Epoch 139/200\n",
            "1/1 - 0s - loss: 0.2259 - binary_accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
            "Epoch 140/200\n",
            "1/1 - 0s - loss: 0.2257 - binary_accuracy: 0.7500 - 42ms/epoch - 42ms/step\n",
            "Epoch 141/200\n",
            "1/1 - 0s - loss: 0.2255 - binary_accuracy: 0.7500 - 22ms/epoch - 22ms/step\n",
            "Epoch 142/200\n",
            "1/1 - 0s - loss: 0.2253 - binary_accuracy: 0.7500 - 21ms/epoch - 21ms/step\n",
            "Epoch 143/200\n",
            "1/1 - 0s - loss: 0.2252 - binary_accuracy: 0.7500 - 19ms/epoch - 19ms/step\n",
            "Epoch 144/200\n",
            "1/1 - 0s - loss: 0.2250 - binary_accuracy: 0.7500 - 33ms/epoch - 33ms/step\n",
            "Epoch 145/200\n",
            "1/1 - 0s - loss: 0.2248 - binary_accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
            "Epoch 146/200\n",
            "1/1 - 0s - loss: 0.2246 - binary_accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
            "Epoch 147/200\n",
            "1/1 - 0s - loss: 0.2244 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
            "Epoch 148/200\n",
            "1/1 - 0s - loss: 0.2243 - binary_accuracy: 0.7500 - 18ms/epoch - 18ms/step\n",
            "Epoch 149/200\n",
            "1/1 - 0s - loss: 0.2241 - binary_accuracy: 0.7500 - 19ms/epoch - 19ms/step\n",
            "Epoch 150/200\n",
            "1/1 - 0s - loss: 0.2239 - binary_accuracy: 0.7500 - 21ms/epoch - 21ms/step\n",
            "Epoch 151/200\n",
            "1/1 - 0s - loss: 0.2237 - binary_accuracy: 0.7500 - 23ms/epoch - 23ms/step\n",
            "Epoch 152/200\n",
            "1/1 - 0s - loss: 0.2235 - binary_accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
            "Epoch 153/200\n",
            "1/1 - 0s - loss: 0.2234 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
            "Epoch 154/200\n",
            "1/1 - 0s - loss: 0.2232 - binary_accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
            "Epoch 155/200\n",
            "1/1 - 0s - loss: 0.2230 - binary_accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
            "Epoch 156/200\n",
            "1/1 - 0s - loss: 0.2228 - binary_accuracy: 0.7500 - 23ms/epoch - 23ms/step\n",
            "Epoch 157/200\n",
            "1/1 - 0s - loss: 0.2226 - binary_accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
            "Epoch 158/200\n",
            "1/1 - 0s - loss: 0.2224 - binary_accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
            "Epoch 159/200\n",
            "1/1 - 0s - loss: 0.2222 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
            "Epoch 160/200\n",
            "1/1 - 0s - loss: 0.2220 - binary_accuracy: 0.7500 - 21ms/epoch - 21ms/step\n",
            "Epoch 161/200\n",
            "1/1 - 0s - loss: 0.2218 - binary_accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
            "Epoch 162/200\n",
            "1/1 - 0s - loss: 0.2216 - binary_accuracy: 0.7500 - 19ms/epoch - 19ms/step\n",
            "Epoch 163/200\n",
            "1/1 - 0s - loss: 0.2214 - binary_accuracy: 0.7500 - 20ms/epoch - 20ms/step\n",
            "Epoch 164/200\n",
            "1/1 - 0s - loss: 0.2212 - binary_accuracy: 0.7500 - 19ms/epoch - 19ms/step\n",
            "Epoch 165/200\n",
            "1/1 - 0s - loss: 0.2210 - binary_accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
            "Epoch 166/200\n",
            "1/1 - 0s - loss: 0.2209 - binary_accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
            "Epoch 167/200\n",
            "1/1 - 0s - loss: 0.2207 - binary_accuracy: 0.7500 - 20ms/epoch - 20ms/step\n",
            "Epoch 168/200\n",
            "1/1 - 0s - loss: 0.2205 - binary_accuracy: 0.7500 - 31ms/epoch - 31ms/step\n",
            "Epoch 169/200\n",
            "1/1 - 0s - loss: 0.2203 - binary_accuracy: 0.7500 - 19ms/epoch - 19ms/step\n",
            "Epoch 170/200\n",
            "1/1 - 0s - loss: 0.2201 - binary_accuracy: 0.7500 - 18ms/epoch - 18ms/step\n",
            "Epoch 171/200\n",
            "1/1 - 0s - loss: 0.2199 - binary_accuracy: 0.7500 - 32ms/epoch - 32ms/step\n",
            "Epoch 172/200\n",
            "1/1 - 0s - loss: 0.2197 - binary_accuracy: 0.7500 - 31ms/epoch - 31ms/step\n",
            "Epoch 173/200\n",
            "1/1 - 0s - loss: 0.2195 - binary_accuracy: 0.7500 - 26ms/epoch - 26ms/step\n",
            "Epoch 174/200\n",
            "1/1 - 0s - loss: 0.2192 - binary_accuracy: 0.7500 - 22ms/epoch - 22ms/step\n",
            "Epoch 175/200\n",
            "1/1 - 0s - loss: 0.2190 - binary_accuracy: 0.7500 - 42ms/epoch - 42ms/step\n",
            "Epoch 176/200\n",
            "1/1 - 0s - loss: 0.2188 - binary_accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
            "Epoch 177/200\n",
            "1/1 - 0s - loss: 0.2186 - binary_accuracy: 0.7500 - 21ms/epoch - 21ms/step\n",
            "Epoch 178/200\n",
            "1/1 - 0s - loss: 0.2184 - binary_accuracy: 0.7500 - 29ms/epoch - 29ms/step\n",
            "Epoch 179/200\n",
            "1/1 - 0s - loss: 0.2182 - binary_accuracy: 0.7500 - 28ms/epoch - 28ms/step\n",
            "Epoch 180/200\n",
            "1/1 - 0s - loss: 0.2180 - binary_accuracy: 0.7500 - 20ms/epoch - 20ms/step\n",
            "Epoch 181/200\n",
            "1/1 - 0s - loss: 0.2178 - binary_accuracy: 0.7500 - 23ms/epoch - 23ms/step\n",
            "Epoch 182/200\n",
            "1/1 - 0s - loss: 0.2176 - binary_accuracy: 0.7500 - 19ms/epoch - 19ms/step\n",
            "Epoch 183/200\n",
            "1/1 - 0s - loss: 0.2174 - binary_accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
            "Epoch 184/200\n",
            "1/1 - 0s - loss: 0.2171 - binary_accuracy: 0.7500 - 24ms/epoch - 24ms/step\n",
            "Epoch 185/200\n",
            "1/1 - 0s - loss: 0.2169 - binary_accuracy: 0.7500 - 30ms/epoch - 30ms/step\n",
            "Epoch 186/200\n",
            "1/1 - 0s - loss: 0.2167 - binary_accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
            "Epoch 187/200\n",
            "1/1 - 0s - loss: 0.2165 - binary_accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
            "Epoch 188/200\n",
            "1/1 - 0s - loss: 0.2163 - binary_accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
            "Epoch 189/200\n",
            "1/1 - 0s - loss: 0.2161 - binary_accuracy: 0.7500 - 12ms/epoch - 12ms/step\n",
            "Epoch 190/200\n",
            "1/1 - 0s - loss: 0.2158 - binary_accuracy: 0.7500 - 21ms/epoch - 21ms/step\n",
            "Epoch 191/200\n",
            "1/1 - 0s - loss: 0.2156 - binary_accuracy: 0.7500 - 25ms/epoch - 25ms/step\n",
            "Epoch 192/200\n",
            "1/1 - 0s - loss: 0.2154 - binary_accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
            "Epoch 193/200\n",
            "1/1 - 0s - loss: 0.2152 - binary_accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
            "Epoch 194/200\n",
            "1/1 - 0s - loss: 0.2150 - binary_accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
            "Epoch 195/200\n",
            "1/1 - 0s - loss: 0.2148 - binary_accuracy: 0.7500 - 10ms/epoch - 10ms/step\n",
            "Epoch 196/200\n",
            "1/1 - 0s - loss: 0.2145 - binary_accuracy: 0.7500 - 14ms/epoch - 14ms/step\n",
            "Epoch 197/200\n",
            "1/1 - 0s - loss: 0.2143 - binary_accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
            "Epoch 198/200\n",
            "1/1 - 0s - loss: 0.2141 - binary_accuracy: 0.7500 - 20ms/epoch - 20ms/step\n",
            "Epoch 199/200\n",
            "1/1 - 0s - loss: 0.2138 - binary_accuracy: 0.7500 - 11ms/epoch - 11ms/step\n",
            "Epoch 200/200\n",
            "1/1 - 0s - loss: 0.2136 - binary_accuracy: 0.7500 - 15ms/epoch - 15ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8239ab3c10>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.history\n",
        "# list all data in history\n",
        "print(history.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfDZMgQnSV6x",
        "outputId": "41a560da-9d29-4eb4-fc0f-4972bfc26a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': [0.25512298941612244, 0.25472936034202576, 0.2543359100818634, 0.25394517183303833, 0.25355836749076843, 0.25317874550819397, 0.2528022825717926, 0.25242942571640015, 0.25206315517425537, 0.25170034170150757, 0.25134098529815674, 0.2509889602661133, 0.2506457567214966, 0.2503061294555664, 0.2499696910381317, 0.24963657557964325, 0.24930697679519653, 0.2489810436964035, 0.2486613392829895, 0.2483452558517456, 0.24803230166435242, 0.2477225959300995, 0.24741749465465546, 0.24711768329143524, 0.2468215823173523, 0.246529221534729, 0.2462405562400818, 0.2459556758403778, 0.24567610025405884, 0.24540016055107117, 0.24512706696987152, 0.24485841393470764, 0.24459420144557953, 0.24433346092700958, 0.24407614767551422, 0.24382227659225464, 0.2435724288225174, 0.24332782626152039, 0.24308592081069946, 0.24284586310386658, 0.242610901594162, 0.24237892031669617, 0.24214975535869598, 0.24192342162132263, 0.24169987440109253, 0.2414790689945221, 0.24126151204109192, 0.2410467118024826, 0.24083521962165833, 0.24062645435333252, 0.2404194474220276, 0.24021568894386292, 0.24001416563987732, 0.23981478810310364, 0.2396175116300583, 0.23942315578460693, 0.23922976851463318, 0.2390393316745758, 0.23885104060173035, 0.2386646568775177, 0.2384800761938095, 0.23829704523086548, 0.23811551928520203, 0.23793549835681915, 0.2377568781375885, 0.23758019506931305, 0.2374044805765152, 0.2372458577156067, 0.23706957697868347, 0.23689132928848267, 0.23672418296337128, 0.23655802011489868, 0.23639261722564697, 0.23622794449329376, 0.23606406152248383, 0.2359009087085724, 0.2357383668422699, 0.23557710647583008, 0.2354154884815216, 0.23525503277778625, 0.23509499430656433, 0.23493531346321106, 0.23477599024772644, 0.2346174567937851, 0.23445867002010345, 0.23430052399635315, 0.23415052890777588, 0.2339903861284256, 0.23383209109306335, 0.23367755115032196, 0.23352275788784027, 0.23336775600910187, 0.23321294784545898, 0.23305751383304596, 0.2329021394252777, 0.2327464520931244, 0.23259034752845764, 0.23243394494056702, 0.23227711021900177, 0.23211979866027832, 0.23196206986904144, 0.23180386424064636, 0.23165075480937958, 0.23148877918720245, 0.2313733994960785, 0.23121589422225952, 0.23103627562522888, 0.23088854551315308, 0.23075801134109497, 0.23061135411262512, 0.23045006394386292, 0.23027664422988892, 0.2301129251718521, 0.22996112704277039, 0.22980935871601105, 0.22966840863227844, 0.229509174823761, 0.22934746742248535, 0.22919124364852905, 0.22903311252593994, 0.2288731187582016, 0.22871144115924835, 0.22854803502559662, 0.2283831089735031, 0.2282213419675827, 0.22805637121200562, 0.22788475453853607, 0.22771556675434113, 0.22754615545272827, 0.22737525403499603, 0.22721892595291138, 0.2270488142967224, 0.22688278555870056, 0.2267099916934967, 0.22653543949127197, 0.22637125849723816, 0.22619804739952087, 0.22602848708629608, 0.22585748136043549, 0.22568759322166443, 0.22551432251930237, 0.2253352254629135, 0.2251582145690918, 0.2249855399131775, 0.22480615973472595, 0.22462037205696106, 0.22444124519824982, 0.22425854206085205, 0.22407564520835876, 0.22389942407608032, 0.22371511161327362, 0.2235383540391922, 0.2233530879020691, 0.2231566607952118, 0.2229723334312439, 0.22278359532356262, 0.22259381413459778, 0.2224092185497284, 0.22222095727920532, 0.22202567756175995, 0.22183379530906677, 0.22164583206176758, 0.22144588828086853, 0.22124916315078735, 0.22104987502098083, 0.22085629403591156, 0.22065415978431702, 0.22046121954917908, 0.220266193151474, 0.22005358338356018, 0.2198600172996521, 0.21966442465782166, 0.21945521235466003, 0.21924260258674622, 0.2190372496843338, 0.21883751451969147, 0.21862995624542236, 0.21842053532600403, 0.21821123361587524, 0.21799904108047485, 0.21778404712677002, 0.2175702452659607, 0.2173662930727005, 0.21714815497398376, 0.21691961586475372, 0.21670258045196533, 0.21649569272994995, 0.21626776456832886, 0.21605180203914642, 0.21584263443946838, 0.21562016010284424, 0.21539047360420227, 0.21516890823841095, 0.21496334671974182, 0.2147504687309265, 0.2145228236913681, 0.2142896056175232, 0.21406355500221252, 0.2138497680425644, 0.21362745761871338], 'binary_accuracy': [0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(training_data).round())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDFAWLDtS-sK",
        "outputId": "20852155-c5ac-499b-af9c-adbb28ee2952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 332ms/step\n",
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(training_data).round())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T31FLpNHT9xy",
        "outputId": "c41c0b38-ece7-41d4-d45e-16cb34dd39f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 59ms/step\n",
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ]
        }
      ]
    }
  ]
}